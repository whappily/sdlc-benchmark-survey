
@Article{	  agrawal2023guiding,
  title		= {Guiding language models of code with global context using
		  monitors},
  author	= {Agrawal, Lakshya A and Kanade, Aditya and Goyal, Navin and
		  Lahiri, Shuvendu K and Rajamani, Sriram K},
  journal	= {arXiv preprint arXiv:2306.10763},
  year		= {2023},
  pdf		= {https://arxiv.org/pdf/2306.10763},
  citations	= {22}
}

@InProceedings{	  armengol2022exebench,
  title		= {ExeBench: an ML-scale dataset of executable C functions},
  author	= {Armengol-Estap{\'e}, Jordi and Woodruff, Jackson and
		  Brauckmann, Alexander and Magalh{\~a}es, Jos{\'e} Wesley de
		  Souza and O'Boyle, Michael FP},
  booktitle	= {Proceedings of the 6th ACM SIGPLAN International Symposium
		  on Machine Programming},
  pages		= {50--59},
  year		= {2022}
}

@Article{	  athiwaratkun2022multilingualeo,
  title		= {Multi-lingual Evaluation of Code Generation Models},
  author	= {Ben Athiwaratkun and Sanjay Krishna Gouda and Zijian Wang
		  and Xiaopeng Li and Yuchen Tian and Ming Tan and Wasi Uddin
		  Ahmad and Shiqi Wang and Qing Sun and Mingyue Shang and
		  Sujan Kumar Gonugondla and Hantian Ding and Varun Kumar and
		  Nathan Fulton and Arash Farahani and Siddharth Jain and
		  Robert Giaquinto and Haifeng Qian and Murali Krishna
		  Ramanathan and Ramesh Nallapati and Baishakhi Ray and
		  Parminder Bhatia and Sudipta Sengupta and Dan Roth and Bing
		  Xiang},
  journal	= {ArXiv},
  year		= {2022},
  volume	= {abs/2210.14868},
  url		= {https://api.semanticscholar.org/CorpusID:253116642}
}

@Article{	  austin2021program,
  author	= {Austin, Jacob and Odena, Augustus and Nye, Maxwell and
		  Bosma, Maarten and Michalewski, Henryk and Dohan, David and
		  Jiang, Ellen and Cai, Carrie and Terry, Michael and Le,
		  Quoc and others},
  citations	= {1247},
  journal	= {arXiv preprint arXiv:2108.07732},
  pdf		= {https://arxiv.org/pdf/2108.07732},
  title		= {Program synthesis with large language models},
  year		= {2021}
}

@InProceedings{	  bui2022vul4j,
  title		= {Vul4j: A dataset of reproducible java vulnerabilities
		  geared towards the study of program repair techniques},
  author	= {Bui, Quang-Cuong and Scandariato, Riccardo and Ferreyra,
		  Nicol{\'a}s E D{\'\i}az},
  booktitle	= {Proceedings of the 19th International Conference on Mining
		  Software Repositories},
  pages		= {464--468},
  year		= {2022}
}

@Article{	  lin2024there,
  title		= {There are More Fish in the Sea: Automated Vulnerability
		  Repair via Binary Templates},
  author	= {Lin, Bo and Wang, Shangwen and Chen, Liqian and Mao,
		  Xiaoguang},
  journal	= {arXiv preprint arXiv:2411.18088},
  year		= {2024}
}

@Article{	  cassano2024knowledge,
  title		= {Knowledge transfer from high-resource to low-resource
		  programming languages for code llms},
  author	= {Cassano, Federico and Gouwar, John and Lucchetti,
		  Francesca and Schlesinger, Claire and Freeman, Anders and
		  Anderson, Carolyn Jane and Feldman, Molly Q and Greenberg,
		  Michael and Jangda, Abhinav and Guha, Arjun},
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {8},
  number	= {OOPSLA2},
  pages		= {677--708},
  year		= {2024},
  publisher	= {ACM New York, NY, USA}
}

@Article{	  chai2024mceval,
  title		= {McEval: Massively Multilingual Code Evaluation},
  author	= {Chai, Linzheng and Liu, Shukai and Yang, Jian and Yin,
		  Yuwei and Jin, Ke and Liu, Jiaheng and Sun, Tao and Zhang,
		  Ge and Ren, Changyu and Guo, Hongcheng and others},
  journal	= {arXiv preprint arXiv:2406.07436},
  year		= {2024}
}

@Article{	  chakraborty2021deep,
  author	= {Chakraborty, Saikat and Krishna, Rahul and Ding, Yangruibo
		  and Ray, Baishakhi},
  citations	= {569},
  journal	= {IEEE Transactions on Software Engineering},
  number	= {9},
  pages		= {3280--3296},
  pdf		= {https://arxiv.org/pdf/2009.07235},
  publisher	= {IEEE},
  title		= {Deep learning based vulnerability detection: Are we there
		  yet?},
  volume	= {48},
  year		= {2021}
}

@Article{	  chen2021evaluating,
  abstract	= {},
  author	= {Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan,
		  Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan,
		  Jared and Edwards, Harri and Burda, Yuri and Joseph,
		  Nicholas and Brockman, Greg and others},
  citations	= {3429},
  journal	= {arXiv preprint arXiv:2107.03374},
  pdf		= {https://arxiv.org/pdf/2107.03374.pdf?spm=a2c6h.13046898.publish-article.19.6cd56ffaIPu4NQ&file=2107.03374},
  title		= {Evaluating large language models trained on code},
  year		= {2021}
}

@InProceedings{	  chen2023diversevul,
  title		= {Diversevul: A new vulnerable source code dataset for deep
		  learning based vulnerability detection},
  author	= {Chen, Yizheng and Ding, Zhoujie and Alowain, Lamya and
		  Chen, Xinyun and Wagner, David},
  booktitle	= {Proceedings of the 26th International Symposium on
		  Research in Attacks, Intrusions and Defenses},
  pages		= {654--668},
  year		= {2023}
}

@InProceedings{	  chen2024rmcbench,
  title		= {RMCBench: Benchmarking Large Language Models' Resistance
		  to Malicious Code},
  author	= {Chen, Jiachi and Zhong, Qingyuan and Wang, Yanlin and
		  Ning, Kaiwen and Liu, Yongkun and Xu, Zenan and Zhao, Zhe
		  and Chen, Ting and Zheng, Zibin},
  booktitle	= {Proceedings of the 39th IEEE/ACM International Conference
		  on Automated Software Engineering},
  pages		= {995--1006},
  year		= {2024}
}

@InProceedings{	  deka2017rico,
  title		= {Rico: A mobile app dataset for building data-driven design
		  applications},
  author	= {Deka, Biplab and Huang, Zifeng and Franzen, Chad and
		  Hibschman, Joshua and Afergan, Daniel and Li, Yang and
		  Nichols, Jeffrey and Kumar, Ranjitha},
  booktitle	= {Proceedings of the 30th annual ACM symposium on user
		  interface software and technology},
  pages		= {845--854},
  year		= {2017}
}

@Article{	  deng2020structure,
  title		= {Structure-grounded pretraining for text-to-SQL},
  author	= {Deng, Xiang and Awadallah, Ahmed Hassan and Meek,
		  Christopher and Polozov, Oleksandr and Sun, Huan and
		  Richardson, Matthew},
  journal	= {arXiv preprint arXiv:2010.12773},
  year		= {2020}
}

@Article{	  ding2024crosscodeeval,
  title		= {Crosscodeeval: A diverse and multilingual benchmark for
		  cross-file code completion},
  author	= {Ding, Yangruibo and Wang, Zijian and Ahmad, Wasi and Ding,
		  Hantian and Tan, Ming and Jain, Nihal and Ramanathan,
		  Murali Krishna and Nallapati, Ramesh and Bhatia, Parminder
		  and Roth, Dan and others},
  journal	= {Advances in Neural Information Processing Systems},
  volume	= {36},
  year		= {2024}
}

@Article{	  ding2024vulnerability,
  title		= {Vulnerability detection with code language models: How far
		  are we?},
  author	= {Ding, Yangruibo and Fu, Yanjun and Ibrahim, Omniyyah and
		  Sitawarin, Chawin and Chen, Xinyun and Alomair, Basel and
		  Wagner, David and Ray, Baishakhi and Chen, Yizheng},
  journal	= {arXiv preprint arXiv:2403.18624},
  year		= {2024}
}

@Article{	  du2023classeval,
  title		= {Classeval: A manually-crafted benchmark for evaluating
		  llms on class-level code generation},
  author	= {Du, Xueying and Liu, Mingwei and Wang, Kaixin and Wang,
		  Hanlin and Liu, Junwei and Chen, Yixuan and Feng, Jiayi and
		  Sha, Chaofeng and Peng, Xin and Lou, Yiling},
  journal	= {arXiv preprint arXiv:2308.01861},
  year		= {2023}
}

@InProceedings{	  fan2020ac,
  author	= {Fan, Jiahao and Li, Yi and Wang, Shaohua and Nguyen, Tien
		  N},
  booktitle	= {Proceedings of the 17th International Conference on Mining
		  Software Repositories},
  citations	= {359},
  pages		= {508--512},
  pdf		= {https://drive.google.com/file/d/1kvJU7newtyIQXdnl1sdvTBXuYTvxQBoG/view},
  title		= {AC/C++ code vulnerability dataset with code changes and
		  CVE summaries},
  year		= {2020}
}

@Article{	  fraser2014large,
  title		= {A large-scale evaluation of automated unit test generation
		  using evosuite},
  author	= {Fraser, Gordon and Arcuri, Andrea},
  journal	= {ACM Transactions on Software Engineering and Methodology
		  (TOSEM)},
  volume	= {24},
  number	= {2},
  pages		= {1--42},
  year		= {2014},
  publisher	= {ACM New York, NY, USA}
}

@Article{	  gan2021exploring,
  title		= {Exploring underexplored limitations of cross-domain
		  text-to-SQL generalization},
  author	= {Gan, Yujian and Chen, Xinyun and Purver, Matthew},
  journal	= {arXiv preprint arXiv:2109.05157},
  year		= {2021}
}

@Article{	  gan2021towards,
  title		= {Towards robustness of text-to-SQL models against synonym
		  substitution},
  author	= {Gan, Yujian and Chen, Xinyun and Huang, Qiuping and
		  Purver, Matthew and Woodward, John R and Xie, Jinxia and
		  Huang, Pengsheng},
  journal	= {arXiv preprint arXiv:2106.01065},
  year		= {2021}
}

@InProceedings{	  gu2018deep,
  author	= {Gu, Xiaodong and Zhang, Hongyu and Kim, Sunghun},
  booktitle	= {Proceedings of the 40th International Conference on
		  Software Engineering},
  citations	= {641},
  pages		= {933--944},
  pdf		= {https://www.researchgate.net/profile/Hongyu-Zhang-46/publication/325732005_Deep_code_search/links/5b29dcfb4585150c633faa57/Deep-code-search.pdf},
  title		= {Deep code search},
  year		= {2018}
}

@Article{	  gu2024cruxeval,
  title		= {Cruxeval: A benchmark for code reasoning, understanding
		  and execution},
  author	= {Gu, Alex and Rozi{\`e}re, Baptiste and Leather, Hugh and
		  Solar-Lezama, Armando and Synnaeve, Gabriel and Wang, Sida
		  I},
  journal	= {arXiv preprint arXiv:2401.03065},
  year		= {2024},
  pdf		= {https://arxiv.org/pdf/2401.03065},
  citations	= {42}
}

@InProceedings{	  hashemi2024logpm,
  title		= {LogPM: Character-Based Log Parser Benchmark},
  author	= {Hashemi, Shayan and Nyyss{\"o}l{\"a}, Jesse and
		  M{\"a}ntyl{\"a}, Mika V},
  booktitle	= {2024 IEEE International Conference on Software Analysis,
		  Evolution and Reengineering (SANER)},
  pages		= {705--710},
  year		= {2024},
  organization	= {IEEE}
}

@InProceedings{	  hellendoorn2019global,
  author	= {Hellendoorn, Vincent J and Sutton, Charles and Singh,
		  Rishabh and Maniatis, Petros and Bieber, David},
  booktitle	= {International conference on learning representations},
  citations	= {270},
  pdf		= {https://openreview.net/pdf?id=B1lnbRNtwr},
  title		= {Global relational models of source code},
  year		= {2019}
}

@Article{	  hendrycks2021measuringcc,
  title		= {Measuring Coding Challenge Competence With APPS},
  author	= {Dan Hendrycks and Steven Basart and Saurav Kadavath and
		  Mantas Mazeika and Akul Arora and Ethan Guo and Collin
		  Burns and Samir Puranik and Horace He and Dawn Xiaodong
		  Song and Jacob Steinhardt},
  journal	= {ArXiv},
  year		= {2021},
  volume	= {abs/2105.09938},
  url		= {https://api.semanticscholar.org/CorpusID:234790100}
}

@InProceedings{	  hu2018deep,
  author	= {Hu, Xing and Li, Ge and Xia, Xin and Lo, David and Jin,
		  Zhi},
  booktitle	= {Proceedings of the 26th conference on program
		  comprehension},
  citations	= {779},
  pages		= {200--210},
  pdf		= {https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=5295&context=sis_research},
  title		= {Deep code comment generation},
  year		= {2018}
}

@Article{	  hu2018summarizing,
  author	= {Hu, Xing and Li, Ge and Xia, Xin and Lo, David and Lu,
		  Shuai and Jin, Zhi},
  citations	= {325},
  pdf		= {https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=5298&context=sis_research},
  title		= {Summarizing source code with transferred api knowledge},
  year		= {2018}
}

@InProceedings{	  hu2019re,
  title		= {Re-factoring based program repair applied to programming
		  assignments},
  author	= {Hu, Yang and Ahmed, Umair Z and Mechtaev, Sergey and
		  Leong, Ben and Roychoudhury, Abhik},
  booktitle	= {2019 34th IEEE/ACM International Conference on Automated
		  Software Engineering (ASE)},
  pages		= {388--398},
  year		= {2019},
  organization	= {IEEE}
}

@Article{	  huang2021cosqa,
  title		= {Cosqa: 20,000+ web queries for code search and question
		  answering},
  author	= {Huang, Junjie and Tang, Duyu and Shou, Linjun and Gong,
		  Ming and Xu, Ke and Jiang, Daxin and Zhou, Ming and Duan,
		  Nan},
  journal	= {arXiv preprint arXiv:2105.13239},
  year		= {2021}
}

@Article{	  husain2019codesearchnet,
  title		= {Codesearchnet challenge: Evaluating the state of semantic
		  code search},
  author	= {Husain, Hamel and Wu, Ho-Hsiang and Gazit, Tiferet and
		  Allamanis, Miltiadis and Brockschmidt, Marc},
  journal	= {arXiv preprint arXiv:1909.09436},
  year		= {2019},
  pdf		= {https://arxiv.org/pdf/1909.09436},
  citations	= {1066}
}

@InProceedings{	  iyer2016summarizing,
  author	= {Iyer, Srinivasan and Konstas, Ioannis and Cheung, Alvin
		  and Zettlemoyer, Luke},
  booktitle	= {54th Annual Meeting of the Association for Computational
		  Linguistics 2016},
  citations	= {875},
  organization	= {Association for Computational Linguistics},
  pages		= {2073--2083},
  pdf		= {https://researchportal.hw.ac.uk/files/25373770/P16_1195.pdf},
  title		= {Summarizing source code using a neural attention model},
  year		= {2016}
}

@Article{	  iyer2018mapping,
  abstract	= {},
  author	= {Iyer, Srinivasan and Konstas, Ioannis and Cheung, Alvin
		  and Zettlemoyer, Luke},
  citations	= {255},
  journal	= {arXiv preprint arXiv:1808.09588},
  pdf		= {https://arxiv.org/pdf/1808.09588},
  title		= {Mapping language to code in programmatic context},
  year		= {2018}
}

@InProceedings{	  jain2023transformer,
  title		= {A Transformer-Based Approach for Abstractive Summarization
		  of Requirements from Obligations in Software Engineering
		  Contracts},
  booktitle	= {2023 {{IEEE}} 31st {{International Requirements
		  Engineering Conference}} ({{RE}})},
  author	= {Jain, Chirag and Anish, Preethu Rose and Singh, Amrita and
		  Ghaisas, Smita},
  year		= {2023},
  month		= sep,
  pages		= {169--179},
  issn		= {2332-6441},
  doi		= {10.1109/RE57278.2023.00025},
  urldate	= {2024-12-25}
}

@InProceedings{	  jiang2024large,
  title		= {A large-scale evaluation for log parsing techniques: How
		  far are we?},
  author	= {Jiang, Zhihan and Liu, Jinyang and Huang, Junjie and Li,
		  Yichen and Huo, Yintong and Gu, Jiazhen and Chen, Zhuangbin
		  and Zhu, Jieming and Lyu, Michael R},
  booktitle	= {Proceedings of the 33rd ACM SIGSOFT International
		  Symposium on Software Testing and Analysis},
  pages		= {223--234},
  year		= {2024}
}

@InProceedings{	  just2014defects4j,
  author	= {Just, Ren{\'e} and Jalali, Darioush and Ernst, Michael D},
  booktitle	= {Proceedings of the 2014 international symposium on
		  software testing and analysis},
  citations	= {1523},
  pages		= {437--440},
  pdf		= {http://darioush.github.io/papers/issta-2014-1.pdf},
  title		= {Defects4J: A database of existing faults to enable
		  controlled testing studies for Java programs},
  year		= {2014}
}

@Article{	  kande2024security,
  title		= {(Security) Assertions by Large Language Models},
  author	= {Kande, Rahul and Pearce, Hammond and Tan, Benjamin and
		  Dolan-Gavitt, Brendan and Thakur, Shailja and Karri, Ramesh
		  and Rajendran, Jeyavijayan},
  journal	= {IEEE Transactions on Information Forensics and Security},
  year		= {2024},
  publisher	= {IEEE}
}

@InProceedings{	  lai2023ds,
  abstract	= {},
  author	= {Lai, Yuhang and Li, Chengxi and Wang, Yiming and Zhang,
		  Tianyi and Zhong, Ruiqi and Zettlemoyer, Luke and Yih,
		  Wen-tau and Fried, Daniel and Wang, Sida and Yu, Tao},
  booktitle	= {International Conference on Machine Learning},
  citations	= {200},
  organization	= {PMLR},
  pages		= {18319--18345},
  pdf		= {https://proceedings.mlr.press/v202/lai23b/lai23b.pdf},
  title		= {DS-1000: A natural and reliable benchmark for data science
		  code generation},
  year		= {2023}
}

@Article{	  le2015manybugs,
  author	= {Le Goues, Claire and Holtschulte, Neal and Smith, Edward K
		  and Brun, Yuriy and Devanbu, Premkumar and Forrest,
		  Stephanie and Weimer, Westley},
  citations	= {368},
  journal	= {IEEE Transactions on Software Engineering},
  number	= {12},
  pages		= {1236--1256},
  pdf		= {https://ieeexplore.ieee.org/ielaam/32/7349123/7153570-aam.pdf},
  publisher	= {IEEE},
  title		= {The ManyBugs and IntroClass benchmarks for automated
		  repair of C programs},
  volume	= {41},
  year		= {2015}
}

@Article{	  lee2021kaggledbqa,
  title		= {KaggleDBQA: Realistic evaluation of text-to-SQL parsers},
  author	= {Lee, Chia-Hsuan and Polozov, Oleksandr and Richardson,
		  Matthew},
  journal	= {arXiv preprint arXiv:2106.11455},
  year		= {2021}
}

@Article{	  lee2022cs1qa,
  title		= {CS1QA: A dataset for assisting code-based question
		  answering in an introductory programming course},
  author	= {Lee, Changyoon and Seonwoo, Yeon and Oh, Alice},
  journal	= {arXiv preprint arXiv:2210.14494},
  year		= {2022},
  pdf		= {https://arxiv.org/pdf/2210.14494},
  citations	= {11}
}

@Article{	  lee2022ehrsql,
  title		= {Ehrsql: A practical text-to-sql benchmark for electronic
		  health records},
  author	= {Lee, Gyubok and Hwang, Hyeonji and Bae, Seongsu and Kwon,
		  Yeonsu and Shin, Woncheol and Yang, Seongjun and Seo,
		  Minjoon and Kim, Jong-Yeup and Choi, Edward},
  journal	= {Advances in Neural Information Processing Systems},
  volume	= {35},
  pages		= {15589--15601},
  year		= {2022}
}

@InProceedings{	  li2018vuldeepecker,
  title		= {{{VulDeePecker}}: {{A Deep Learning-Based System}} for
		  {{Vulnerability Detection}}},
  booktitle	= {Proceedings 2018 {{Network}} and {{Distributed System
		  Security Symposium}}},
  author	= {Li, Zhen and Zou, Deqing and Xu, Shouhuai and Ou, Xinyu
		  and Jin, Hai and Wang, Sujuan and Deng, Zhijun and Zhong,
		  Yuyi},
  year		= {2018},
  eprint	= {1801.01681},
  primaryclass	= {cs},
  doi		= {10.14722/ndss.2018.23158},
  urldate	= {2024-12-24},
  archiveprefix	= {arXiv}
}

@Article{	  li2021sysevr,
  author	= {Li, Zhen and Zou, Deqing and Xu, Shouhuai and Jin, Hai and
		  Zhu, Yawei and Chen, Zhaoxuan},
  citations	= {705},
  journal	= {IEEE Transactions on Dependable and Secure Computing},
  number	= {4},
  pages		= {2244--2258},
  pdf		= {https://arxiv.org/pdf/1807.06756},
  publisher	= {IEEE},
  title		= {Sysevr: A framework for using deep learning to detect
		  software vulnerabilities},
  volume	= {19},
  year		= {2021}
}

@Article{	  li2022competition,
  abstract	= {},
  author	= {Li, Yujia and Choi, David and Chung, Junyoung and Kushman,
		  Nate and Schrittwieser, Julian and Leblond, R{\'e}mi and
		  Eccles, Tom and Keeling, James and Gimeno, Felix and Dal
		  Lago, Agustin and others},
  citations	= {1016},
  journal	= {Science},
  number	= {6624},
  pages		= {1092--1097},
  pdf		= {https://www.science.org/doi/pdf/10.1126/science.abq1158},
  publisher	= {American Association for the Advancement of Science},
  title		= {Competition-level code generation with alphacode},
  volume	= {378},
  year		= {2022}
}

@Article{	  li2024can,
  author	= {Li, Jinyang and Hui, Binyuan and Qu, Ge and Yang, Jiaxi
		  and Li, Binhua and Li, Bowen and Wang, Bailin and Qin,
		  Bowen and Geng, Ruiying and Huo, Nan and others},
  citations	= {262},
  journal	= {Advances in Neural Information Processing Systems},
  pdf		= {https://proceedings.neurips.cc/paper_files/paper/2023/file/83fc8fab1710363050bbd1d4b8cc0021-Paper-Datasets_and_Benchmarks.pdf},
  title		= {Can llm already serve as a database interface? a big bench
		  for large-scale database grounded text-to-sqls},
  volume	= {36},
  year		= {2024}
}

@InProceedings{	  lin2017quixbugs,
  author	= {Lin, Derrick and Koppel, James and Chen, Angela and
		  Solar-Lezama, Armando},
  booktitle	= {Proceedings Companion of the 2017 ACM SIGPLAN
		  international conference on systems, programming,
		  languages, and applications: software for humanity},
  citations	= {266},
  pages		= {55--56},
  pdf		= {https://dl.acm.org/doi/pdf/10.1145/3135932.3135941},
  title		= {QuixBugs: A multi-lingual program repair benchmark set
		  based on the Quixey Challenge},
  year		= {2017}
}

@Article{	  liu2021codeqa,
  title		= {CodeQA: A question answering dataset for source code
		  comprehension},
  author	= {Liu, Chenxiao and Wan, Xiaojun},
  journal	= {arXiv preprint arXiv:2109.08365},
  year		= {2021},
  pdf		= {https://arxiv.org/pdf/2109.08365},
  citations	= {19}
}

@Article{	  liu2023repobench,
  title		= {Repobench: Benchmarking repository-level code
		  auto-completion systems},
  author	= {Liu, Tianyang and Xu, Canwen and McAuley, Julian},
  journal	= {arXiv preprint arXiv:2306.03091},
  year		= {2023},
  pdf		= {https://arxiv.org/pdf/2306.03091},
  citations	= {72}
}

@InProceedings{	  liu2024coedpilot,
  title		= {CoEdPilot: Recommending Code Edits with Learned Prior Edit
		  Relevance, Project-wise Awareness, and Interactive Nature},
  author	= {Liu, Chenyan and Cai, Yufan and Lin, Yun and Huang, Yuhuan
		  and Pei, Yunrui and Jiang, Bo and Yang, Ping and Dong, Jin
		  Song and Mei, Hong},
  booktitle	= {Proceedings of the 33rd ACM SIGSOFT International
		  Symposium on Software Testing and Analysis},
  pages		= {466--478},
  year		= {2024}
}

@Article{	  liu2024your,
  abstract	= {},
  author	= {Liu, Jiawei and Xia, Chunqiu Steven and Wang, Yuyao and
		  Zhang, Lingming},
  citations	= {617},
  journal	= {Advances in Neural Information Processing Systems},
  pdf		= {https://proceedings.neurips.cc/paper_files/paper/2023/file/43e9d647ccd3e4b7b5baab53f0368686-Paper-Conference.pdf},
  title		= {Is your code generated by chatgpt really correct? rigorous
		  evaluation of large language models for code generation},
  volume	= {36},
  year		= {2024}
}

@Article{	  lu2021codexglue,
  author	= {Lu, Shuai and Guo, Daya and Ren, Shuo and Huang, Junjie
		  and Svyatkovskiy, Alexey and Blanco, Ambrosio and Clement,
		  Colin and Drain, Dawn and Jiang, Daxin and Tang, Duyu and
		  others},
  citations	= {827},
  journal	= {arXiv preprint arXiv:2102.04664},
  pdf		= {https://arxiv.org/pdf/2102.04664},
  title		= {Codexglue: A machine learning benchmark dataset for code
		  understanding and generation},
  year		= {2021}
}

@InProceedings{	  madeiral2019bears,
  title		= {Bears: An extensible java bug benchmark for automatic
		  program repair studies},
  author	= {Madeiral, Fernanda and Urli, Simon and Maia, Marcelo and
		  Monperrus, Martin},
  booktitle	= {2019 IEEE 26th international conference on software
		  analysis, evolution and reengineering (SANER)},
  pages		= {468--478},
  year		= {2019},
  organization	= {IEEE}
}

@InProceedings{	  min-etal-2019-pilot,
  title		= {A Pilot Study for {C}hinese {SQL} Semantic Parsing},
  author	= {Min, Qingkai and Shi, Yuefeng and Zhang, Yue},
  editor	= {Inui, Kentaro and Jiang, Jing and Ng, Vincent and Wan,
		  Xiaojun},
  booktitle	= {Proceedings of the 2019 Conference on Empirical Methods in
		  Natural Language Processing and the 9th International Joint
		  Conference on Natural Language Processing (EMNLP-IJCNLP)},
  month		= nov,
  year		= {2019},
  address	= {Hong Kong, China},
  publisher	= {Association for Computational Linguistics},
  url		= {https://aclanthology.org/D19-1377/},
  doi		= {10.18653/v1/D19-1377},
  pages		= {3652--3658},
  abstract	= {The task of semantic parsing is highly useful for dialogue
		  and question answering systems. Many datasets have been
		  proposed to map natural language text into SQL, among which
		  the recent Spider dataset provides cross-domain samples
		  with multiple tables and complex queries. We build a Spider
		  dataset for Chinese, which is currently a low-resource
		  language in this task area. Interesting research questions
		  arise from the uniqueness of the language, which requires
		  word segmentation, and also from the fact that SQL keywords
		  and columns of DB tables are typically written in English.
		  We compare character- and word-based encoders for a
		  semantic parser, and different embedding schemes. Results
		  show that word-based semantic parser is subject to
		  segmentation errors and cross-lingual word embeddings are
		  useful for text-to-SQL.}
}

@InProceedings{	  mou2016convolutional,
  title		= {Convolutional neural networks over tree structures for
		  programming language processing},
  author	= {Mou, Lili and Li, Ge and Zhang, Lu and Wang, Tao and Jin,
		  Zhi},
  booktitle	= {Proceedings of the AAAI conference on artificial
		  intelligence},
  volume	= {30},
  number	= {1},
  year		= {2016}
}

@Article{	  muennighoff2023octopack,
  title		= {Octopack: Instruction tuning code large language models},
  author	= {Muennighoff, Niklas and Liu, Qian and Zebaze, Armel and
		  Zheng, Qinkai and Hui, Binyuan and Zhuo, Terry Yue and
		  Singh, Swayam and Tang, Xiangru and Von Werra, Leandro and
		  Longpre, Shayne},
  journal	= {arXiv preprint arXiv:2308.07124},
  year		= {2023}
}

@Article{	  naman2024livecodebench,
  title		= {Livecodebench: Holistic and contamination free evaluation
		  of large language models for code},
  author	= {Naman Jain, King Han and Gu, Alex and Li, Wen-Ding and
		  Yan, Fanjia and Zhang, Tianjun and Wang, Sida and
		  Solar-Lezama, Armando and Sen, Koushik and Stoica, Ion},
  journal	= {arXiv preprint arXiv:2403.07974},
  year		= {2024}
}

@InProceedings{	  ni2022best,
  title		= {The best of both worlds: integrating semantic features
		  with expert features for defect prediction and
		  localization},
  author	= {Ni, Chao and Wang, Wei and Yang, Kaiwen and Xia, Xin and
		  Liu, Kui and Lo, David},
  booktitle	= {Proceedings of the 30th ACM Joint European Software
		  Engineering Conference and Symposium on the Foundations of
		  Software Engineering},
  pages		= {672--683},
  year		= {2022}
}

@InProceedings{	  nikitopoulos2021crossvul,
  title		= {CrossVul: a cross-language vulnerability dataset with
		  commit data},
  author	= {Nikitopoulos, Georgios and Dritsa, Konstantina and
		  Louridas, Panos and Mitropoulos, Dimitris},
  booktitle	= {Proceedings of the 29th ACM Joint Meeting on European
		  Software Engineering Conference and Symposium on the
		  Foundations of Software Engineering},
  pages		= {1565--1569},
  year		= {2021}
}

@InProceedings{	  pan2023measuring,
  title		= {Measuring Efficient Code Generation with GEC},
  author	= {Pan, Yue and Lyu, Chen},
  booktitle	= {Proceedings of the 14th Asia-Pacific Symposium on
		  Internetware},
  pages		= {249--258},
  year		= {2023}
}

@Article{	  puri2021codenet,
  title		= {Codenet: A large-scale ai for code dataset for learning a
		  diversity of coding tasks},
  author	= {Puri, Ruchir and Kung, David S and Janssen, Geert and
		  Zhang, Wei and Domeniconi, Giacomo and Zolotov, Vladimir
		  and Dolby, Julian and Chen, Jie and Choudhury, Mihir and
		  Decker, Lindsey and others},
  journal	= {arXiv preprint arXiv:2105.12655},
  year		= {2021}
}

@Article{	  quan2025codeelo,
  title		= {CodeElo: Benchmarking Competition-level Code Generation of
		  LLMs with Human-comparable Elo Ratings},
  author	= {Quan, Shanghaoran and Yang, Jiaxi and Yu, Bowen and Zheng,
		  Bo and Liu, Dayiheng and Yang, An and Ren, Xuancheng and
		  Gao, Bofei and Miao, Yibo and Feng, Yunlong and others},
  journal	= {arXiv preprint arXiv:2501.01257},
  year		= {2025}
}

@Article{	  ranaldi2024investigating,
  title		= {Investigating the Impact of Data Contamination of Large
		  Language Models in Text-to-SQL Translation},
  author	= {Ranaldi, Federico and Ruzzetti, Elena Sofia and Onorati,
		  Dario and Ranaldi, Leonardo and Giannone, Cristina and
		  Favalli, Andrea and Romagnoli, Raniero and Zanzotto, Fabio
		  Massimo},
  journal	= {arXiv preprint arXiv:2402.08100},
  year		= {2024}
}

@InProceedings{	  saha2018bugs,
  author	= {Saha, Ripon K and Lyu, Yingjun and Lam, Wing and Yoshida,
		  Hiroaki and Prasad, Mukul R},
  booktitle	= {Proceedings of the 15th international conference on mining
		  software repositories},
  citations	= {215},
  pages		= {10--13},
  pdf		= {http://mir.cs.illinois.edu/winglam/publications/2018/bugs-dot-jar.pdf},
  title		= {Bugs. jar: A large-scale, diverse dataset of real-world
		  java bugs},
  year		= {2018}
}

@InProceedings{	  she2024wadec,
  title		= {WaDec: Decompiling WebAssembly Using Large Language
		  Model},
  author	= {She, Xinyu and Zhao, Yanjie and Wang, Haoyu},
  booktitle	= {Proceedings of the 39th IEEE/ACM International Conference
		  on Automated Software Engineering},
  pages		= {481--492},
  year		= {2024}
}

@Article{	  tang2024biocoder,
  title		= {BioCoder: a benchmark for bioinformatics code generation
		  with large language models},
  author	= {Tang, Xiangru and Qian, Bill and Gao, Rick and Chen,
		  Jiakang and Chen, Xinyun and Gerstein, Mark B},
  journal	= {Bioinformatics},
  volume	= {40},
  number	= {Supplement\_1},
  pages		= {i266--i276},
  year		= {2024},
  publisher	= {Oxford University Press}
}

@InProceedings{	  tihanyi2023formai,
  title		= {The formai dataset: Generative ai in software security
		  through the lens of formal verification},
  author	= {Tihanyi, Norbert and Bisztray, Tamas and Jain, Ridhi and
		  Ferrag, Mohamed Amine and Cordeiro, Lucas C and Mavroeidis,
		  Vasileios},
  booktitle	= {Proceedings of the 19th International Conference on
		  Predictive Models and Data Analytics in Software
		  Engineering},
  pages		= {33--43},
  year		= {2023}
}

@InProceedings{	  tufano2022methods2test,
  title		= {Methods2Test: A dataset of focal methods mapped to test
		  cases},
  author	= {Tufano, Michele and Deng, Shao Kun and Sundaresan, Neel
		  and Svyatkovskiy, Alexey},
  booktitle	= {Proceedings of the 19th International Conference on Mining
		  Software Repositories},
  pages		= {299--303},
  year		= {2022}
}

@Article{	  waghjale2024ecco,
  title		= {ECCO: Can We Improve Model-Generated Code Efficiency
		  Without Sacrificing Functional Correctness?},
  author	= {Waghjale, Siddhant and Veerendranath, Vishruth and Wang,
		  Zora Zhiruo and Fried, Daniel},
  journal	= {arXiv preprint arXiv:2407.14044},
  year		= {2024}
}

@InProceedings{	  wang-etal-2023-recode,
  title		= {{R}e{C}ode: Robustness Evaluation of Code Generation
		  Models},
  author	= {Wang, Shiqi and Li, Zheng and Qian, Haifeng and Yang,
		  Chenghao and Wang, Zijian and Shang, Mingyue and Kumar,
		  Varun and Tan, Samson and Ray, Baishakhi and Bhatia,
		  Parminder and Nallapati, Ramesh and Ramanathan, Murali
		  Krishna and Roth, Dan and Xiang, Bing},
  editor	= {Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki},
  booktitle	= {Proceedings of the 61st Annual Meeting of the Association
		  for Computational Linguistics (Volume 1: Long Papers)},
  month		= jul,
  year		= {2023},
  address	= {Toronto, Canada},
  publisher	= {Association for Computational Linguistics},
  url		= {https://aclanthology.org/2023.acl-long.773},
  doi		= {10.18653/v1/2023.acl-long.773},
  pages		= {13818--13843}
}

@Article{	  wei2020lambdanet,
  title		= {Lambdanet: Probabilistic type inference using graph neural
		  networks},
  author	= {Wei, Jiayi and Goyal, Maruth and Durrett, Greg and Dillig,
		  Isil},
  journal	= {arXiv preprint arXiv:2005.02161},
  year		= {2020},
  pdf		= {https://arxiv.org/pdf/2005.02161},
  citations	= {134}
}

@InProceedings{	  wei2024coeditor,
  title		= {Coeditor: Leveraging Repo-level Diffs for Code
		  Auto-editing},
  author	= {Jiayi Wei and Greg Durrett and Isil Dillig},
  booktitle	= {The Twelfth International Conference on Learning
		  Representations},
  year		= {2024},
  url		= {https://openreview.net/forum?id=ALVwQjZRS8}
}

@InProceedings{	  wu2023effective,
  title		= {How effective are neural networks for fixing security
		  vulnerabilities},
  author	= {Wu, Yi and Jiang, Nan and Pham, Hung Viet and Lutellier,
		  Thibaud and Davis, Jordan and Tan, Lin and Babkin, Petr and
		  Shah, Sameena},
  booktitle	= {Proceedings of the 32nd ACM SIGSOFT International
		  Symposium on Software Testing and Analysis},
  pages		= {1282--1294},
  year		= {2023}
}

@Article{	  xu2024distinguishing,
  title		= {Distinguishing LLM-generated from Human-written Code by
		  Contrastive Learning},
  author	= {Xu, Xiaodan and Ni, Chao and Guo, Xinrong and Liu,
		  Shaoxuan and Wang, Xiaoya and Liu, Kui and Yang, Xiaohu},
  journal	= {ACM Transactions on Software Engineering and Methodology},
  year		= {2024},
  publisher	= {ACM New York, NY}
}

@Article{	  yang2024evaluating,
  title		= {Evaluating and aligning codellms on human preference},
  author	= {Yang, Jian and Yang, Jiaxi and Jin, Ke and Miao, Yibo and
		  Zhang, Lei and Yang, Liqun and Cui, Zeyu and Zhang, Yichang
		  and Hui, Binyuan and Lin, Junyang},
  journal	= {arXiv preprint arXiv:2412.05210},
  year		= {2024}
}

@InProceedings{	  yin2018learning,
  author	= {Yin, Pengcheng and Deng, Bowen and Chen, Edgar and
		  Vasilescu, Bogdan and Neubig, Graham},
  title		= {Learning to Mine Aligned Code and Natural Language Pairs
		  from Stack Overflow},
  booktitle	= {International Conference on Mining Software Repositories},
  series	= {MSR},
  pages		= {476--486},
  year		= {2018},
  publisher	= {ACM},
  doi		= {https://doi.org/10.1145/3196398.3196408}
}

@Article{	  yu2018spider,
  author	= {Yu, Tao and Zhang, Rui and Yang, Kai and Yasunaga,
		  Michihiro and Wang, Dongxu and Li, Zifan and Ma, James and
		  Li, Irene and Yao, Qingning and Roman, Shanelle and
		  others},
  citations	= {1155},
  journal	= {arXiv preprint arXiv:1809.08887},
  pdf		= {https://arxiv.org/pdf/1809.08887},
  title		= {Spider: A large-scale human-labeled dataset for complex
		  and cross-domain semantic parsing and text-to-sql task},
  year		= {2018}
}

@Article{	  yu2019cosql,
  title		= {Cosql: A conversational text-to-sql challenge towards
		  cross-domain natural language interfaces to databases},
  author	= {Yu, Tao and Zhang, Rui and Er, He Yang and Li, Suyi and
		  Xue, Eric and Pang, Bo and Lin, Xi Victoria and Tan, Yi
		  Chern and Shi, Tianze and Li, Zihan and others},
  journal	= {arXiv preprint arXiv:1909.05378},
  year		= {2019}
}

@Article{	  yu2019sparc,
  title		= {Sparc: Cross-domain semantic parsing in context},
  author	= {Yu, Tao and Zhang, Rui and Yasunaga, Michihiro and Tan, Yi
		  Chern and Lin, Xi Victoria and Li, Suyi and Er, Heyang and
		  Li, Irene and Pang, Bo and Chen, Tao and others},
  journal	= {arXiv preprint arXiv:1906.02285},
  year		= {2019}
}

@Article{	  zhang2023repocoder,
  title		= {Repocoder: Repository-level code completion through
		  iterative retrieval and generation},
  author	= {Zhang, Fengji and Chen, Bei and Zhang, Yue and Keung,
		  Jacky and Liu, Jin and Zan, Daoguang and Mao, Yi and Lou,
		  Jian-Guang and Chen, Weizhu},
  journal	= {arXiv preprint arXiv:2303.12570},
  year		= {2023},
  pdf		= {https://arxiv.org/pdf/2303.12570},
  citations	= {164}
}

@Article{	  zheng2023codegeex,
  author	= {Zheng, Qinkai and Xia, Xiao and Zou, Xu and Dong, Yuxiao
		  and Wang, Shan and Xue, Yufei and Wang, Zihan and Shen, Lei
		  and Wang, Andi and Li, Yang and others},
  citations	= {218},
  journal	= {arXiv preprint arXiv:2303.17568},
  pdf		= {none},
  title		= {Codegeex: A pre-trained model for code generation with
		  multilingual evaluations on humaneval-x},
  year		= {2023}
}

@Article{	  zhong2017seq2sql,
  author	= {Zhong, Victor and Xiong, Caiming and Socher, Richard},
  citations	= {1216},
  journal	= {arXiv preprint arXiv:1709.00103},
  pdf		= {https://arxiv.org/pdf/1709.00103},
  title		= {Seq2sql: Generating structured queries from natural
		  language using reinforcement learning},
  year		= {2017}
}

@InProceedings{	  zhong2024can,
  title		= {Can LLM Replace Stack Overflow? A Study on Robustness and
		  Reliability of Large Language Model Code Generation},
  author	= {Zhong, Li and Wang, Zilong},
  booktitle	= {Proceedings of the AAAI Conference on Artificial
		  Intelligence},
  volume	= {38},
  number	= {19},
  pages		= {21841--21849},
  year		= {2024}
}

@Article{	  zhou2019devign,
  author	= {Zhou, Yaqin and Liu, Shangqing and Siow, Jingkai and Du,
		  Xiaoning and Liu, Yang},
  citations	= {981},
  journal	= {Advances in neural information processing systems},
  pdf		= {https://proceedings.neurips.cc/paper_files/paper/2019/file/49265d2447bc3bbfe9e76306ce40a31f-Paper.pdf},
  title		= {Devign: Effective vulnerability identification by learning
		  comprehensive program semantics via graph neural networks},
  volume	= {32},
  year		= {2019}
}

@InProceedings{	  zhu2023loghub,
  title		= {Loghub: A large collection of system log datasets for
		  ai-driven log analytics},
  author	= {Zhu, Jieming and He, Shilin and He, Pinjia and Liu,
		  Jinyang and Lyu, Michael R},
  booktitle	= {2023 IEEE 34th International Symposium on Software
		  Reliability Engineering (ISSRE)},
  pages		= {355--366},
  year		= {2023},
  organization	= {IEEE}
}

@Article{	  zhuang2021software,
  title		= {Software vulnerability detection via deep learning over
		  disaggregated code graph representation},
  author	= {Zhuang, Yufan and Suneja, Sahil and Thost, Veronika and
		  Domeniconi, Giacomo and Morari, Alessandro and Laredo,
		  Jim},
  journal	= {arXiv preprint arXiv:2109.03341},
  year		= {2021}
}

@Article{	  zhuo2024bigcodebench,
  title		= {Bigcodebench: Benchmarking code generation with diverse
		  function calls and complex instructions},
  author	= {Zhuo, Terry Yue and Vu, Minh Chien and Chim, Jenny and Hu,
		  Han and Yu, Wenhao and Widyasari, Ratnadira and Yusuf, Imam
		  Nur Bani and Zhan, Haolan and He, Junda and Paul, Indraneil
		  and others},
  journal	= {arXiv preprint arXiv:2406.15877},
  year		= {2024}
}

@Article{	  zou2019mu,
  title		= {$\mu$ VulDeePecker: A Deep Learning-Based System for
		  Multiclass Vulnerability Detection},
  author	= {Zou, Deqing and Wang, Sujuan and Xu, Shouhuai and Li, Zhen
		  and Jin, Hai},
  journal	= {IEEE Transactions on Dependable and Secure Computing},
  volume	= {18},
  number	= {5},
  pages		= {2224--2236},
  year		= {2019},
  publisher	= {IEEE}
}

@Article{	  zou2023universal,
  title		= {Universal and transferable adversarial attacks on aligned
		  language models},
  author	= {Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr,
		  Milad and Kolter, J Zico and Fredrikson, Matt},
  journal	= {arXiv preprint arXiv:2307.15043},
  year		= {2023}
}

@Article{	  guo2024redcode,
  title		= {RedCode: Risky Code Execution and Generation Benchmark for
		  Code Agents},
  author	= {Guo, Chengquan and Liu, Xun and Xie, Chulin and Zhou, Andy
		  and Zeng, Yi and Lin, Zinan and Song, Dawn and Li, Bo},
  journal	= {arXiv preprint arXiv:2411.07781},
  year		= {2024}
}

@InProceedings{	  gu2019empirical,
  title		= {An empirical study on api-misuse bugs in open-source c
		  programs},
  author	= {Gu, Zuxing and Wu, Jiecheng and Liu, Jiaxiang and Zhou,
		  Min and Gu, Ming},
  booktitle	= {2019 IEEE 43rd annual computer software and applications
		  conference (COMPSAC)},
  volume	= {1},
  pages		= {11--20},
  year		= {2019},
  organization	= {IEEE}
}

@InProceedings{	  rodriguez2023benchmarking,
  title		= {Benchmarking causal study to interpret large language
		  models for source code},
  author	= {Rodriguez-Cardenas, Daniel and Palacio, David N and Khati,
		  Dipin and Burke, Henry and Poshyvanyk, Denys},
  booktitle	= {2023 IEEE International Conference on Software Maintenance
		  and Evolution (ICSME)},
  pages		= {329--334},
  year		= {2023},
  organization	= {IEEE}
}

@InProceedings{	  wang2021screen2words,
  title		= {Screen2words: Automatic mobile UI summarization with
		  multimodal learning},
  author	= {Wang, Bryan and Li, Gang and Zhou, Xin and Chen, Zhourong
		  and Grossman, Tovi and Li, Yang},
  booktitle	= {The 34th Annual ACM Symposium on User Interface Software
		  and Technology},
  pages		= {498--510},
  year		= {2021}
}

@Article{	  wartschinski2022vudenc,
  title		= {VUDENC: vulnerability detection with deep learning on a
		  natural codebase for Python},
  author	= {Wartschinski, Laura and Noller, Yannic and Vogel, Thomas
		  and Kehrer, Timo and Grunske, Lars},
  journal	= {Information and Software Technology},
  volume	= {144},
  pages		= {106809},
  year		= {2022},
  publisher	= {Elsevier}
}

@InProceedings{	  bhandari2021cvefixes,
  title		= {CVEfixes: automated collection of vulnerabilities and
		  their fixes from open-source software},
  author	= {Bhandari, Guru and Naseer, Amara and Moonen, Leon},
  booktitle	= {Proceedings of the 17th International Conference on
		  Predictive Models and Data Analytics in Software
		  Engineering},
  pages		= {30--39},
  year		= {2021}
}

@Article{	  nguyen2024gptsniffer,
  title		= {GPTSniffer: A CodeBERT-based classifier to detect source
		  code written by ChatGPT},
  author	= {Nguyen, Phuong T and Di Rocco, Juri and Di Sipio, Claudio
		  and Rubei, Riccardo and Di Ruscio, Davide and Di Penta,
		  Massimiliano},
  journal	= {Journal of Systems and Software},
  volume	= {214},
  pages		= {112059},
  year		= {2024},
  publisher	= {Elsevier}
}

@Article{	  zhu2024domaineval,
  title		= {DOMAINEVAL: An Auto-Constructed Benchmark for Multi-Domain
		  Code Generation},
  author	= {Zhu, Qiming and Cao, Jialun and Lu, Yaojie and Lin, Hongyu
		  and Han, Xianpei and Sun, Le and Cheung, Shing-Chi},
  journal	= {arXiv preprint arXiv:2408.13204},
  year		= {2024}
}

@InProceedings{	  yu2024codereval,
  title		= {Codereval: A benchmark of pragmatic code generation with
		  generative pre-trained models},
  author	= {Yu, Hao and Shen, Bo and Ran, Dezhi and Zhang, Jiaxin and
		  Zhang, Qi and Ma, Yuchi and Liang, Guangtai and Li, Ying
		  and Wang, Qianxiang and Xie, Tao},
  booktitle	= {Proceedings of the 46th IEEE/ACM International Conference
		  on Software Engineering},
  pages		= {1--12},
  year		= {2024}
}

@Article{	  li2024evocodebench,
  title		= {Evocodebench: An evolving code generation benchmark
		  aligned with real-world code repositories},
  author	= {Li, Jia and Li, Ge and Zhang, Xuanming and Dong, Yihong
		  and Jin, Zhi},
  journal	= {arXiv preprint arXiv:2404.00599},
  year		= {2024}
}

@Article{	  zheng2024towards,
  title		= {Towards more realistic evaluation of LLM-based code
		  generation: an experimental study and beyond},
  author	= {Zheng, Dewu and Wang, Yanlin and Shi, Ensheng and Zhang,
		  Ruikai and Ma, Yuchi and Zhang, Hongyu and Zheng, Zibin},
  journal	= {arXiv preprint arXiv:2406.06918},
  year		= {2024}
}

@InProceedings{	  ferrari2017pure,
  title		= {{{PURE}}: {{A Dataset}} of {{Public Requirements
		  Documents}}},
  booktitle	= {2017 {{IEEE}} 25th {{International Requirements
		  Engineering Conference}} ({{RE}})},
  author	= {Ferrari, Alessio and Spagnolo, Giorgio Oronzo and Gnesi,
		  Stefania},
  year		= {2017},
  month		= sep,
  pages		= {502--505},
  issn		= {2332-6441},
  doi		= {10.1109/RE.2017.29},
  urldate	= {2025-03-24}
}

@Misc{		  sayyad2005,
  author	= "Sayyad Shirabad, J. and Menzies, T.J.",
  year		= "2005",
  title		= "{The PROMISE Repository of Software Engineering
		  Databases.}",
  url		= "http://promise.site.uottawa.ca/SERepository",
  howpublished	= "School of Information Technology and Engineering,
		  University of Ottawa, Canada"
}

@Misc{		  hu2024self,
  title		= {Self-{{Evolving Multi-Agent Collaboration Networks}} for
		  {{Software Development}}},
  author	= {Hu, Yue and Cai, Yuzhu and Du, Yaxin and Zhu, Xinyu and
		  Liu, Xiangrui and Yu, Zijie and Hou, Yuchen and Tang, Shuo
		  and Chen, Siheng},
  year		= {2024},
  month		= oct,
  number	= {arXiv:2410.16946},
  eprint	= {2410.16946},
  primaryclass	= {cs},
  publisher	= {arXiv},
  doi		= {10.48550/arXiv.2410.16946},
  urldate	= {2025-03-24},
  archiveprefix	= {arXiv}
}

@Article{	  ma2024speceval,
  title		= {SpecEval: Evaluating Code Comprehension in Large Language
		  Models via Program Specifications},
  author	= {Ma, Lezhi and Liu, Shangqing and Bu, Lei and Li, Shangru
		  and Wang, Yida and Liu, Yang},
  journal	= {arXiv preprint arXiv:2409.12866},
  year		= {2024}
}

@Article{	  miah2024user,
  title		= {User-centric evaluation of ChatGPT capability of
		  generating R program code},
  author	= {Miah, Tanha and Zhu, Hong},
  journal	= {arXiv e-prints},
  pages		= {arXiv--2402},
  year		= {2024}
}

@Article{	  agashe2019juice,
  title		= {JuICe: A large scale distantly supervised dataset for open
		  domain context-based code generation},
  author	= {Agashe, Rajas and Iyer, Srinivasan and Zettlemoyer, Luke},
  journal	= {arXiv preprint arXiv:1910.02216},
  year		= {2019}
}

@Article{	  xie2024codebenchgen,
  title		= {Codebenchgen: Creating scalable execution-based code
		  generation benchmarks},
  author	= {Xie, Yiqing and Xie, Alex and Sheth, Divyanshu and Liu,
		  Pengfei and Fried, Daniel and Rose, Carolyn},
  journal	= {arXiv preprint arXiv:2404.00566},
  year		= {2024}
}

@Article{	  li2025infibench,
  title		= {Infibench: Evaluating the question-answering capabilities
		  of code large language models},
  author	= {Li, Linyi and Geng, Shijie and Li, Zhenwen and He, Yibo
		  and Yu, Hao and Hua, Ziyue and Ning, Guanghan and Wang,
		  Siwei and Xie, Tao and Yang, Hongxia},
  journal	= {Advances in Neural Information Processing Systems},
  volume	= {37},
  pages		= {128668--128698},
  year		= {2025}
}

@InProceedings{	  ezzini2023ai,
  title		= {Ai-based question answering assistance for analyzing
		  natural-language requirements},
  author	= {Ezzini, Saad and Abualhaija, Sallam and Arora, Chetan and
		  Sabetzadeh, Mehrdad},
  booktitle	= {2023 IEEE/ACM 45th International Conference on Software
		  Engineering (ICSE)},
  pages		= {1277--1289},
  year		= {2023},
  organization	= {IEEE}
}

@Article{	  moran2018machine,
  title		= {Machine learning-based prototyping of graphical user
		  interfaces for mobile apps},
  author	= {Moran, Kevin and Bernal-C{\'a}rdenas, Carlos and Curcio,
		  Michael and Bonett, Richard and Poshyvanyk, Denys},
  journal	= {IEEE transactions on software engineering},
  volume	= {46},
  number	= {2},
  pages		= {196--221},
  year		= {2018},
  publisher	= {IEEE}
}

@Article{	  weiguingmobilegui2024,
  title		= {GUing: a mobile GUI search engine using a vision-language
		  model},
  author	= {Wei, Jialiang and Courbis, Anne-Lise and Lambolais, Thomas
		  and Xu, Binbin and Bernard, Pierre Louis and Dray, G\'erard
		  and Maalej, Walid},
  date		= {2024-11-08},
  journaltitle	= {ACM Trans. Softw. Eng. Methodol.},
  shortjournal	= {ACM Trans, Softw, Eng, Methodol,},
  issn		= {1049-331X},
  doi		= {10.1145/3702993}
}

@Article{	  dongcodescore2024,
  title		= {Codescore: Evaluating code generation by learning code
		  execution},
  author	= {Dong, Yihong and Ding, Jiazheng and Jiang, Xue and Li, Ge
		  and Li, Zhuo and Jin, Zhi},
  journal	= {ACM Transactions on Software Engineering and Methodology},
  volume	= {34},
  number	= {3},
  pages		= {1--22},
  year		= {2025},
  publisher	= {ACM New York, NY}
}

@Article{	  liuyour2023,
  title		= {Is your code generated by chatgpt really correct? rigorous
		  evaluation of large language models for code generation},
  author	= {Liu, Jiawei and Xia, Chunqiu Steven and Wang, Yuyao and
		  Zhang, Lingming},
  date		= {2023},
  journaltitle	= {Advances in Neural Information Processing Systems},
  volume	= {36},
  pages		= {21558--21572},
  url		= {https://proceedings.neurips.cc/paper_files/paper/2023/hash/43e9d647ccd3e4b7b5baab53f0368686-Abstract-Conference.html},
  urldate	= {2025-03-03}
}

@InProceedings{	  jimenezswebenchcanlanguage2023,
  title		= {SWE-bench: can language models resolve real-world github
		  issues?},
  author	= {Jimenez, Carlos E. and Yang, John and Wettig, Alexander
		  and Yao, Shunyu and Pei, Kexin and Press, Ofir and
		  Narasimhan, Karthik R.},
  date		= {2023-10-13},
  url		= {https://openreview.net/forum?id=VTF8yNQM66},
  urldate	= {2025-02-24},
  eventtitle	= {The Twelfth International Conference on Learning
		  Representations}
}

@InProceedings{	  liu2023verilogeval,
  title		= {Verilogeval: Evaluating large language models for verilog
		  code generation},
  author	= {Liu, Mingjie and Pinckney, Nathaniel and Khailany, Brucek
		  and Ren, Haoxing},
  booktitle	= {2023 IEEE/ACM International Conference on Computer Aided
		  Design (ICCAD)},
  pages		= {1--8},
  year		= {2023},
  organization	= {IEEE}
}

@InProceedings{	  allam2024rtl,
  title		= {Rtl-repo: A benchmark for evaluating llms on large-scale
		  rtl design projects},
  author	= {Allam, Ahmed and Shalan, Mohamed},
  booktitle	= {2024 IEEE LLM Aided Design Workshop (LAD)},
  pages		= {1--5},
  year		= {2024},
  organization	= {IEEE}
}

@Article{	  sumitani2024chibench,
  title		= {ChiBench: a Benchmark Suite for Testing Electronic Design
		  Automation Tools},
  author	= {Sumitani, Rafael and Amorim, Jo{\~a}o Victor and Mafra,
		  Augusto and Crepalde, Mirlaine and Pereira, Fernando Magno
		  Quint{\~a}o},
  journal	= {arXiv preprint arXiv:2406.06550},
  year		= {2024}
}

@Article{	  kang2024fveval,
  title		= {FVEval: Understanding Language Model Capabilities in
		  Formal Verification of Digital Hardware},
  author	= {Kang, Minwoo and Liu, Mingjie and Hamad, Ghaith Bany and
		  Suhaib, Syed and Ren, Haoxing},
  journal	= {arXiv preprint arXiv:2410.23299},
  year		= {2024}
}

@Article{	  chen2024roboscript,
  title		= {Roboscript: Code generation for free-form manipulation
		  tasks across real and simulation},
  author	= {Chen, Junting and Mu, Yao and Yu, Qiaojun and Wei,
		  Tianming and Wu, Silang and Yuan, Zhecheng and Liang,
		  Zhixuan and Yang, Chao and Zhang, Kaipeng and Shao, Wenqi
		  and others},
  journal	= {arXiv preprint arXiv:2402.14623},
  year		= {2024}
}

@Article{	  hsueh2022systematic,
  title		= {Systematic comparison of path planning algorithms using
		  PathBench},
  author	= {Hsueh, Hao-Ya and Toma, Alexandru-Iosif and Ali Jaafar,
		  Hussein and Stow, Edward and Murai, Riku and Kelly, Paul HJ
		  and Saeedi, Sajad},
  journal	= {Advanced Robotics},
  volume	= {36},
  number	= {11},
  pages		= {566--581},
  year		= {2022},
  publisher	= {Taylor \& Francis}
}

@InProceedings{	  mayer2024cobra,
  title		= {CoBRA: A composable benchmark for robotics applications},
  author	= {Mayer, Matthias and K{\"u}lz, Jonathan and Althoff,
		  Matthias},
  booktitle	= {2024 IEEE International Conference on Robotics and
		  Automation (ICRA)},
  pages		= {17665--17671},
  year		= {2024},
  organization	= {IEEE}
}

@InProceedings{	  gonzalez-pumariega2025robotouille,
  title		= {Robotouille: An Asynchronous Planning Benchmark for {LLM}
		  Agents},
  author	= {Gonzalo Gonzalez-Pumariega and Leong Su Yean and Neha
		  Sunkara and Sanjiban Choudhury},
  booktitle	= {The Thirteenth International Conference on Learning
		  Representations},
  year		= {2025},
  url		= {https://openreview.net/forum?id=OhUoTMxFIH}
}

@Article{	  damen2022rescaling,
  title		= {Rescaling egocentric vision: Collection, pipeline and
		  challenges for epic-kitchens-100},
  author	= {Damen, Dima and Doughty, Hazel and Farinella, Giovanni
		  Maria and Furnari, Antonino and Kazakos, Evangelos and Ma,
		  Jian and Moltisanti, Davide and Munro, Jonathan and
		  Perrett, Toby and Price, Will and others},
  journal	= {International Journal of Computer Vision},
  pages		= {1--23},
  year		= {2022},
  publisher	= {Springer}
}

@Article{	  cassano2022multipl,
  title		= {Multipl-e: A scalable and extensible approach to
		  benchmarking neural code generation},
  author	= {Cassano, Federico and Gouwar, John and Nguyen, Daniel and
		  Nguyen, Sydney and Phipps-Costin, Luna and Pinckney, Donald
		  and Yee, Ming-Ho and Zi, Yangtian and Anderson, Carolyn
		  Jane and Feldman, Molly Q and others},
  journal	= {arXiv preprint arXiv:2208.08227},
  year		= {2022}
}

@Article{	  tao2024unraveling,
  title		= {Unraveling the Potential of Large Language Models in Code
		  Translation: How Far Are We?},
  author	= {Tao, Qingxiao and Yu, Tingrui and Gu, Xiaodong and Shen,
		  Beijun},
  journal	= {arXiv preprint arXiv:2410.09812},
  year		= {2024}
}

@Article{	  fu2023codeapex,
  title		= {Codeapex: A bilingual programming evaluation benchmark for
		  large language models},
  author	= {Fu, Lingyue and Chai, Huacan and Luo, Shuang and Du,
		  Kounianhua and Zhang, Weiming and Fan, Longteng and Lei,
		  Jiayi and Rui, Renting and Lin, Jianghao and Fang, Yuchen
		  and others},
  journal	= {arXiv preprint arXiv:2309.01940},
  year		= {2023}
}

@Article{	  hu2024real,
  title		= {A Real-World Benchmark for Evaluating Fine-Grained Issue
		  Solving Capabilities of Large Language Models},
  author	= {Hu, Ruida and Peng, Chao and Ren, Jingyi and Jiang, Bo and
		  Meng, Xiangxin and Wu, Qinyun and Gao, Pengfei and Wang,
		  Xinchen and Gao, Cuiyun},
  journal	= {arXiv preprint arXiv:2411.18019},
  year		= {2024}
}

@Article{	  gao2021beyond,
  title		= {Beyond tests: Program vulnerability repair via crash
		  constraint extraction},
  author	= {Gao, Xiang and Wang, Bo and Duck, Gregory J and Ji, Ruyi
		  and Xiong, Yingfei and Roychoudhury, Abhik},
  journal	= {ACM Transactions on Software Engineering and Methodology
		  (TOSEM)},
  volume	= {30},
  number	= {2},
  pages		= {1--27},
  year		= {2021},
  publisher	= {ACM New York, NY, USA}
}

@InProceedings{	  widyasari2020bugsinpy,
  title		= {Bugsinpy: a database of existing bugs in python programs
		  to enable controlled testing and debugging studies},
  author	= {Widyasari, Ratnadira and Sim, Sheng Qin and Lok, Camellia
		  and Qi, Haodi and Phan, Jack and Tay, Qijin and Tan,
		  Constance and Wee, Fiona and Tan, Jodie Ethelda and Yieh,
		  Yuheng and others},
  booktitle	= {Proceedings of the 28th ACM joint meeting on european
		  software engineering conference and symposium on the
		  foundations of software engineering},
  pages		= {1556--1560},
  year		= {2020}
}

@InProceedings{	  oh2022pyter,
  title		= {PyTER: effective program repair for Python type errors},
  author	= {Oh, Wonseok and Oh, Hakjoo},
  booktitle	= {Proceedings of the 30th ACM Joint European Software
		  Engineering Conference and Symposium on the Foundations of
		  Software Engineering},
  pages		= {922--934},
  year		= {2022}
}

@Article{	  huang2024effibench,
  title		= {Effibench: benchmarking the efficiency of automatically
		  generated code},
  author	= {Huang, Dong and Qing, Yuhao and Shang, Weiyi and Cui,
		  Heming and Zhang, Jie},
  date		= {2024},
  journaltitle	= {Advances in Neural Information Processing Systems},
  shortjournal	= {Adv. Neural Inf. Process. Syst.},
  volume	= {37},
  pages		= {11506--11544},
  url		= {https://proceedings.neurips.cc/paper_files/paper/2024/hash/15807b6e09d691fe5e96cdecde6d7b80-Abstract-Datasets_and_Benchmarks_Track.html},
  urldate	= {2025-03-12}
}

@Article{	  wainakh2019evaluating,
  title		= {Evaluating semantic representations of source code},
  author	= {Wainakh, Yaza and Rauf, Moiz and Pradel, Michael},
  date		= {2019-09-25},
  journaltitle	= {Arxiv},
  shortjournal	= {Arxiv},
  url		= {https://www.semanticscholar.org/paper/Evaluating-Semantic-Representations-of-Source-Code-Wainakh-Rauf/cb66cbcab02f08a2492e0f53983cdd3ec06618f3},
  urldate	= {2025-03-12}
}

@InProceedings{	  li2024deveval,
  title		= "{D}ev{E}val: A Manually-Annotated Code Generation
		  Benchmark Aligned with Real-World Code Repositories",
  author	= "Li, Jia and Li, Ge and Zhao, Yunfei and Li, Yongmin and
		  Liu, Huanyu and Zhu, Hao and Wang, Lecheng and Liu, Kaibo
		  and Fang, Zheng and Wang, Lanshen and Ding, Jiazheng and
		  Zhang, Xuanming and Zhu, Yuqi and Dong, Yihong and Jin, Zhi
		  and Li, Binhua and Huang, Fei and Li, Yongbin and Gu, Bin
		  and Yang, Mengfei",
  editor	= "Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek",
  booktitle	= "Findings of the Association for Computational Linguistics:
		  ACL 2024",
  month		= aug,
  year		= "2024",
  address	= "Bangkok, Thailand",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2024.findings-acl.214/",
  doi		= "10.18653/v1/2024.findings-acl.214",
  pages		= "3603--3614"
}

@Article{	  xu2024cruxeval,
  title		= {CRUXEval-X: A Benchmark for Multilingual Code Reasoning,
		  Understanding and Execution},
  author	= {Xu, Ruiyang and Cao, Jialun and Lu, Yaojie and Lin, Hongyu
		  and Han, Xianpei and He, Ben and Cheung, Shing-Chi and Sun,
		  Le},
  journal	= {arXiv preprint arXiv:2408.13001},
  year		= {2024}
}

@Misc{		  zheng2024beyond,
  title		= {Beyond Correctness: Benchmarking Multi-dimensional Code
		  Generation for Large Language Models},
  author	= {Jiasheng Zheng and Boxi Cao and Zhengzhao Ma and Ruotong
		  Pan and Hongyu Lin and Yaojie Lu and Xianpei Han and Le
		  Sun},
  year		= {2024},
  eprint	= {2407.11470},
  archiveprefix	= {arXiv},
  primaryclass	= {cs.SE},
  url		= {https://arxiv.org/abs/2407.11470}
}

@Article{	  guo2024deepseek,
  title		= {DeepSeek-Coder: When the Large Language Model Meets
		  Programming--The Rise of Code Intelligence},
  author	= {Guo, Daya and Zhu, Qihao and Yang, Dejian and Xie, Zhenda
		  and Dong, Kai and Zhang, Wentao and Chen, Guanting and Bi,
		  Xiao and Wu, Yu and Li, YK and others},
  journal	= {arXiv preprint arXiv:2401.14196},
  year		= {2024}
}

@InProceedings{	  risse2024uncovering,
  title		= {Uncovering the limits of machine learning for automatic
		  vulnerability detection},
  author	= {Risse, Niklas and B{\"o}hme, Marcel},
  booktitle	= {33rd USENIX Security Symposium (USENIX Security 24)},
  pages		= {4247--4264},
  year		= {2024}
}

@InProceedings{	  li2024mmcodea,
  title		= {MMCode: benchmarking multimodal large language models for
		  code generation with visually rich programming problems},
  booktitle	= {Findings of the Association for Computational Linguistics:
		  EMNLP 2024},
  author	= {Li, Kaixin and Tian, Yuchen and Hu, Qisheng and Luo,
		  Ziyang and Huang, Zhiyong and Ma, Jing},
  editor	= {Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung},
  date		= {2024-11},
  pages		= {736--783},
  publisher	= {Association for Computational Linguistics},
  location	= {Miami, Florida, USA},
  doi		= {10.18653/v1/2024.findings-emnlp.42},
  eventtitle	= {Findings 2024}
}

@Article{	  huang2023benchmarking,
  title		= {BENCHMARKING LARGE LANGUAGE MODELS AS AI RESEARCH AGENTS},
  author	= {Huang, Qian and Vora, Jian and Liang, Percy and Leskovec,
		  Jure},
  date		= {2023}
}

@Article{	  mundler2024swtbencha,
  title		= {SWT-bench: testing and validating real-world bug-fixes
		  with code agents},
  author	= {M\"undler, Niels and M\"uller, Mark N. and He, Jingxuan
		  and Vechev, Martin},
  date		= {2024-12-16},
  journaltitle	= {Advances in Neural Information Processing Systems},
  shortjournal	= {Adv. Neural Inf. Process. Syst.},
  volume	= {37},
  pages		= {81857--81887},
  url		= {https://proceedings.neurips.cc/paper_files/paper/2024/hash/94f093b41fc2666376fb1f667fe282f3-Abstract-Conference.html},
  urldate	= {2025-03-17}
}

@Article{	  li2025fea,
  title		= {FEA-Bench: A Benchmark for Evaluating Repository-Level
		  Code Generation for Feature Implementation},
  author	= {Li, Wei and Zhang, Xin and Guo, Zhongxin and Mao,
		  Shaoguang and Luo, Wen and Peng, Guangyue and Huang, Yangyu
		  and Wang, Houfeng and Li, Scarlett},
  journal	= {arXiv preprint arXiv:2503.06680},
  year		= {2025}
}

@Article{	  krishna2024using,
  title		= {Using LLMs in Software Requirements Specifications: An
		  Empirical Evaluation},
  author	= {Krishna, Madhava and Gaur, Bhagesh and Verma, Arsh and
		  Jalote, Pankaj},
  date		= {2024-06-24},
  journaltitle	= {2024 IEEE 32nd International Requirements Engineering
		  Conference (RE)},
  shortjournal	= {2024 IEEE 32nd Int. Requir. Eng. Conf. (RE)},
  pages		= {475--483},
  publisher	= {IEEE},
  location	= {Reykjavik, Iceland},
  doi		= {10.1109/RE59067.2024.00056},
  eventtitle	= {2024 IEEE 32nd International Requirements Engineering
		  Conference (RE)},
  isbn		= {9798350395112}
}

@Article{	  cao2024spider2v,
  title		= {Spider2-v: How far are multimodal agents from automating
		  data science and engineering workflows?},
  author	= {Cao, Ruisheng and Lei, Fangyu and Wu, Haoyuan and Chen,
		  Jixuan and Fu, Yeqiao and Gao, Hongcheng and Xiong,
		  Xinzhuang and Zhang, Hanchong and Hu, Wenjing and Mao,
		  Yuchen},
  date		= {2024},
  journaltitle	= {Advances in Neural Information Processing Systems},
  shortjournal	= {Adv. Neural Inf. Process. Syst.},
  volume	= {37},
  pages		= {107703--107744},
  url		= {https://proceedings.neurips.cc/paper_files/paper/2024/hash/c2f71567cd53464161cab3336e8fc865-Abstract-Datasets_and_Benchmarks_Track.html},
  urldate	= {2025-03-21}
}

@InProceedings{	  neurips2024_cb66be28,
  title		= {Web2Code: a large-scale webpage-to-code dataset and
		  evaluation framework for multimodal llms},
  booktitle	= {Advances in neural information processing systems},
  author	= {Yun, Sukmin and Lin, Haokun and Thushara, Rusiru and Bhat,
		  Mohammad Qazim and Wang, Yongxin and Jiang, Zutao and Deng,
		  Mingkai and Wang, Jinhong and Tao, Tianhua and Li, Junbo
		  and Li, Haonan and Nakov, Preslav and Baldwin, Timothy and
		  Liu, Zhengzhong and Xing, Eric P. and Liang, Xiaodan and
		  Shen, Zhiqiang},
  editor	= {Globerson, A. and Mackey, L. and Belgrave, D. and Fan, A.
		  and Paquet, U. and Tomczak, J. and Zhang, C.},
  date		= {2024},
  volume	= {37},
  pages		= {112134--112157},
  publisher	= {Curran Associates, Inc.},
  url		= {https://proceedings.neurips.cc/paper_files/paper/2024/file/cb66be286795d71f89367d596bf78ea7-Paper-Datasets_and_Benchmarks_Track.pdf}
}

@InProceedings{	  svajlenko2014big,
  title		= {Towards a big data curated benchmark of inter-project code
		  clones},
  booktitle	= {2014 IEEE International Conference on Software Maintenance
		  and Evolution},
  author	= {Svajlenko, Jeffrey and Islam, Judith F. and Keivanloo,
		  Iman and Roy, Chanchal K. and Mia, Mohammad Mamun},
  date		= {2014},
  pages		= {476--480},
  publisher	= {IEEE},
  doi		= {10.1109/ICSME.2014.77}
}

@InProceedings{	  yan2024codescope,
  title		= {{{CodeScope}}: An Execution-Based Multilingual Multitask
		  Multidimensional Benchmark for Evaluating {{LLMs}} on Code
		  Understanding and Generation},
  shorttitle	= {{{CodeScope}}},
  booktitle	= {Proceedings of the 62nd {{Annual Meeting}} of the
		  {{Association}} for {{Computational Linguistics}}
		  ({{Volume}} 1: {{Long Papers}})},
  author	= {Yan, Weixiang and Liu, Haitian and Wang, Yunkun and Li,
		  Yunzhe and Chen, Qian and Wang, Wen and Lin, Tingyu and
		  Zhao, Weishan and Zhu, Li and Sundaram, Hari and Deng,
		  Shuiguang},
  editor	= {Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek},
  date		= {2024-08},
  pages		= {5511--5558},
  publisher	= {Association for Computational Linguistics},
  location	= {Bangkok, Thailand},
  doi		= {10.18653/v1/2024.acl-long.301},
  url		= {https://aclanthology.org/2024.acl-long.301/},
  urldate	= {2025-01-17},
  abstract	= {Large Language Models (LLMs) have demonstrated remarkable
		  performance on assisting humans in programming and
		  facilitating programming automation. However, existing
		  benchmarks for evaluating the code understanding and
		  generation capacities of LLMs suffer from severe
		  limitations. First, most benchmarks are insufficient as
		  they focus on a narrow range of popular programming
		  languages and specific tasks, whereas real-world software
		  development scenarios show a critical need to implement
		  systems with multilingual and multitask programming
		  environments to satisfy diverse requirements. Second, most
		  benchmarks fail to consider the actual executability and
		  the consistency of execution results of the generated code.
		  To bridge these gaps between existing benchmarks and
		  expectations from practical applications, we introduce
		  **CodeScope**, an execution-based, multilingual, multitask,
		  multidimensional evaluation benchmark for comprehensively
		  measuring LLM capabilities on coding tasks. CodeScope
		  covers **43 programming languages** and **eight coding
		  tasks**. It evaluates the coding performance of LLMs from
		  three dimensions (perspectives): **length**,
		  **difficulty**, and **efficiency**. To facilitate
		  execution-based evaluations of code generation, we develop
		  **MultiCodeEngine**, an automated code execution engine
		  that supports 14 programming languages. Finally, we
		  systematically evaluate and analyze eight mainstream LLMs
		  and demonstrate the superior breadth and challenges of
		  CodeScope for evaluating LLMs on code understanding and
		  generation tasks compared to other benchmarks. The
		  CodeScope benchmark and code are publicly available at
		  https://github.com/WeixiangYAN/CodeScope.},
  eventtitle	= {{{ACL}} 2024},
  langid	= {english},
  keywords	= {citationNumber: 0},
  annotation	= {GSCC: 0000015 \\ 0 citations (Crossref/DOI) [2025-01-17]},
  file		= {C:\Users\ADMIN\Zotero\storage\VEKAWV7F\CodeScope An
		  Execution-based Multilingual Multitask Multidimensional
		  Benchmark for Evaluating LLMs.pdf}
}

@Misc{		  khan2023xcodeeval,
  title		= {{{xCodeEval}}: A Large Scale Multilingual Multitask
		  Benchmark for Code Understanding, Generation, Translation
		  and Retrieval},
  author	= {Khan, Mohammad Abdullah Matin and Bari, M. Saiful and Do,
		  Xuan Long and Wang, Weishi and Parvez, Md Rizwan and Joty,
		  Shafiq},
  year		= {2023},
  month		= nov,
  number	= {arXiv:2303.03004},
  eprint	= {2303.03004},
  primaryclass	= {cs},
  publisher	= {arXiv},
  doi		= {10.48550/arXiv.2303.03004},
  urldate	= {2024-12-24},
  archiveprefix	= {arXiv}
}

@InProceedings{	  yan2023codetransocean,
  title		= {{{CodeTransOcean}}: {{A Comprehensive Multilingual
		  Benchmark}} for {{Code Translation}}},
  booktitle	= {Findings of the {{Association}} for {{Computational
		  Linguistics}}: {{EMNLP}} 2023},
  author	= {Yan, Weixiang and Tian, Yuchen and Li, Yunzhe and Chen,
		  Qian and Wang, Wen},
  editor	= {Bouamor, Houda and Pino, Juan and Bali, Kalika},
  year		= {2023},
  month		= dec,
  pages		= {5067--5089},
  publisher	= {Association for Computational Linguistics},
  address	= {Singapore},
  doi		= {10.18653/v1/2023.findings-emnlp.337},
  urldate	= {2025-03-21}
}

@Misc{		  zhou2025lessleakbench,
  title		= {{{LessLeak-Bench}}: {{A First Investigation}} of {{Data
		  Leakage}} in {{LLMs Across}} 83 {{Software Engineering
		  Benchmarks}}},
  author	= {Zhou, Xin and Weyssow, Martin and Widyasari, Ratnadira and
		  Zhang, Ting and He, Junda and Lyu, Yunbo and Chang,
		  Jianming and Zhang, Beiqi and Huang, Dan and Lo, David},
  year		= {2025},
  month		= feb,
  number	= {arXiv:2502.06215},
  eprint	= {2502.06215},
  primaryclass	= {cs},
  publisher	= {arXiv},
  doi		= {10.48550/arXiv.2502.06215},
  urldate	= {2025-03-21},
  archiveprefix	= {arXiv}
}

@Misc{		  si2025design2code,
  title		= {{{Design2Code}}: {{Benchmarking Multimodal Code
		  Generation}} for {{Automated Front-End Engineering}}},
  author	= {Si, Chenglei and Zhang, Yanzhe and Li, Ryan and Yang,
		  Zhengyuan and Liu, Ruibo and Yang, Diyi},
  year		= {2025},
  month		= feb,
  number	= {arXiv:2403.03163},
  eprint	= {2403.03163},
  primaryclass	= {cs},
  publisher	= {arXiv},
  doi		= {10.48550/arXiv.2403.03163},
  urldate	= {2025-03-21},
  archiveprefix	= {arXiv}
}

@InProceedings{	  yang2024matplotagent,
  title		= {{{MatPlotAgent}}: {{Method}} and {{Evaluation}} for
		  {{LLM-Based Agentic Scientific Data Visualization}}},
  booktitle	= {Findings of the {{Association}} for {{Computational
		  Linguistics}}: {{ACL}} 2024},
  author	= {Yang, Zhiyu and Zhou, Zihan and Wang, Shuo and Cong, Xin
		  and Han, Xu and Yan, Yukun and Liu, Zhenghao and Tan,
		  Zhixing and Liu, Pengyuan and Yu, Dong and Liu, Zhiyuan and
		  Shi, Xiaodong and Sun, Maosong},
  editor	= {Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek},
  year		= {2024},
  month		= aug,
  pages		= {11789--11804},
  publisher	= {Association for Computational Linguistics},
  address	= {Bangkok, Thailand},
  doi		= {10.18653/v1/2024.findings-acl.701},
  urldate	= {2025-03-21}
}

@Misc{		  jin2024evaluation,
  title		= {An {{Evaluation}} of {{Requirements Modeling}} for
		  {{Cyber-Physical Systems}} via {{LLMs}}},
  author	= {Jin, Dongming and Zhao, Shengxin and Jin, Zhi and Chen,
		  Xiaohong and Wang, Chunhui and Fang, Zheng and Xiao,
		  Hongbin},
  year		= {2024},
  month		= aug,
  number	= {arXiv:2408.02450},
  eprint	= {2408.02450},
  primaryclass	= {cs},
  publisher	= {arXiv},
  doi		= {10.48550/arXiv.2408.02450},
  urldate	= {2025-03-24},
  archiveprefix	= {arXiv}
}

@Misc{		  reinpold2024exploringa,
  title		= {Exploring LLMs for Verifying Technical System
		  Specifications Against Requirements},
  author	= {Reinpold, Lasse M. and Schieseck, Marvin and Wagner, Lukas
		  P. and Gehlhoff, Felix and Fay, Alexander},
  year		= {2024},
  month		= nov,
  number	= {arXiv:2411.11582},
  eprint	= {2411.11582},
  primaryclass	= {cs},
  publisher	= {arXiv},
  doi		= {10.48550/arXiv.2411.11582},
  urldate	= {2025-03-24},
  archiveprefix	= {arXiv}
}

@InProceedings{	  velickovic2022clrs,
  title		= {The clrs algorithmic reasoning benchmark},
  booktitle	= {International Conference on Machine Learning},
  author	= {Veli\v ckovi\'c, Petar and Badia, Adri\`a Puigdom\`enech
		  and Budden, David and Pascanu, Razvan and Banino, Andrea
		  and Dashevskiy, Misha and Hadsell, Raia and Blundell, Charles},
  date		= {2022},
  pages		= {22084--22102},
  publisher	= {PMLR},
  url		= {https://proceedings.mlr.press/v162/velickovic22a},
  urldate	= {2025-03-25}
}

@InProceedings{	  ferrari2024model,
  title		= {Model Generation with LLMs: From Requirements to UML
		  Sequence Diagrams},
  booktitle	= {2024 IEEE 32nd International Requirements Engineering
		  Conference Workshops (REW)},
  author	= {Ferrari, Alessio and Abualhaija, Sallam and Arora,
		  Chetan},
  date		= {2024-06},
  pages		= {291--300},
  issn		= {2770-6834},
  doi		= {10.1109/REW61692.2024.00044},
  eventtitle	= {2024 IEEE 32nd International Requirements Engineering
		  Conference Workshops (REW)}
}

@Article{	  gong2024cosqa+,
  title		= {CoSQA+: Enhancing Code Search Dataset with Matching Code},
  author	= {Gong, Jing and Wu, Yanghui and Liang, Linxi and Zheng,
		  Zibin and Wang, Yanlin},
  journal	= {arXiv preprint arXiv:2406.11589},
  year		= {2024}
}

@InProceedings{	  chen2024evaluating,
  title		= {Reasoning Runtime Behavior of a Program with LLM: How Far
		  Are We?},
  author	= {Chen, Junkai and Pan, Zhiyuan and Hu, Xing and Li, Zhenhao
		  and Li, Ge and Xia, Xin},
  booktitle	= {Proceedings of the IEEE/ACM 47th International Conference
		  on Software Engineering},
  year		= {2025}
}

@Article{	  li2024devbench,
  title		= {Devbench: A comprehensive benchmark for software
		  development},
  author	= {Li, Bowen and Wu, Wenhan and Tang, Ziwei and Shi, Lin and
		  Yang, John and Li, Jinyang and Yao, Shunyu and Qian, Chen
		  and Hui, Binyuan and Zhang, Qicheng},
  date		= {2024},
  journaltitle	= {ArXiv Prepr. ArXiv240308604},
  volume	= {3},
  eprint	= {2403.08604},
  eprinttype	= {arXiv},
  url		= {https://se-research.bytedance.com/publication/arxiv24a/arxiv24a.pdf},
  urldate	= {2025-04-09},
  language	= {en-US}
}

@Article{	  liu2024evaluating,
  title		= {Evaluating language models for efficient code generation},
  author	= {Liu, Jiawei and Xie, Songrun and Wang, Junhao and Wei,
		  Yuxiang and Ding, Yifeng and Zhang, Lingming},
  journal	= {arXiv preprint arXiv:2408.06450},
  year		= {2024}
}

@Article{	  qiu2024efficient,
  title		= {How efficient is llm-generated code? a rigorous \&
		  high-standard benchmark},
  author	= {Qiu, Ruizhong and Zeng, Weiliang Will and Ezick, James and
		  Lott, Christopher and Tong, Hanghang},
  journal	= {arXiv preprint arXiv:2406.06647},
  year		= {2024}
}

@Misc{		  juliet_java_1.3,
  author	= {Juliet Java 1.3},
  title		= {Juliet Java 1.3},
  year		= {2017},
  howpublished	= {\url{https://samate.nist.gov/SARD/test-suites/111}},
  note		= {Accessed: 12-12-2023}
}

@Article{	  ling2025bias,
  title		= {Bias Unveiled: Investigating Social Bias in LLM-Generated
		  Code},
  author	= {Ling, Lin and Rabbi, Fazle and Wang, Song and Yang,
		  Jinqiu},
  date		= {2025-04-11},
  journaltitle	= {Proceedings of the AAAI Conference on Artificial
		  Intelligence},
  shortjournal	= {Proc. AAAI Conf. Artif. Intell.},
  volume	= {39},
  number	= {26},
  pages		= {27491--27499},
  issn		= {2374-3468},
  doi		= {10.1609/aaai.v39i26.34961},
  issue		= {26},
  language	= {en}
}
@article{zhang2024codeagent,
  title={Codeagent: Enhancing code generation with tool-integrated agent systems for real-world repo-level coding challenges},
  author={Zhang, Kechi and Li, Jia and Li, Ge and Shi, Xianjie and Jin, Zhi},
  journal={arXiv preprint arXiv:2401.07339},
  year={2024}
}
@article{liu2025projecteval,
  title={ProjectEval: A Benchmark for Programming Agents Automated Evaluation on Project-Level Code Generation},
  author={Liu, Kaiyuan and Pan, Youcheng and Li, Jing and He, Daojing and Xiang, Yang and Du, Yexing and Gao, Tianrun},
  journal={arXiv preprint arXiv:2503.07010},
  year={2025}
}
@article{rashid2025swe,
  title={SWE-PolyBench: A multi-language benchmark for repository level evaluation of coding agents},
  author={Rashid, Muhammad Shihab and Bock, Christian and Zhuang, Yuan and Buccholz, Alexander and Esler, Tim and Valentin, Simon and Franceschi, Luca and Wistuba, Martin and Sivaprasad, Prabhu Teja and Kim, Woo Jung and others},
  journal={arXiv preprint arXiv:2504.08703},
  year={2025}
}
@article{zhang2025unveiling,
  title={Unveiling Provider Bias in Large Language Models for Code Generation},
  author={Zhang, Xiaoyu and Zhai, Juan and Ma, Shiqing and Bao, Qingshuang and Jiang, Weipeng and Shen, Chao and Liu, Yang},
  journal={arXiv preprint arXiv:2501.07849},
  year={2025}
}
@article{vergopoulos2025automated,
  title={Automated Benchmark Generation for Repository-Level Coding Tasks},
  author={Vergopoulos, Konstantinos and M{\"u}ller, Mark Niklas and Vechev, Martin},
  journal={arXiv preprint arXiv:2503.07701},
  year={2025}
}